This directory contains legacy game infrastructure code on which a reinforcement learning environment abstraction was built. Using these abstractions, we adapt example implementations (see files and pdf for citations) of Q-learning, policy gradients, and actor-critic models to learn optimal play against heuristics in our betweenness game. We further present an implementation of an approximate betweenness centrality measure with epsilon additive error with at most delta probability. 

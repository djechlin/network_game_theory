{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow.contrib.slim as slim\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc\n",
    "import os\n",
    "\n",
    "from game import *\n",
    "from random import randint\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice([0,1, 2], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rules = Rules()\n",
    "rules.nb_max_step = 100\n",
    "rules.nb_players = 10\n",
    "\n",
    "game1 = Game()\n",
    "game1.rules = rules\n",
    "\n",
    "player1 = Player()\n",
    "player1.rules = rules\n",
    "player1.type = EntityType.competitive_player\n",
    "\n",
    "game1.add_player(player1)\n",
    "\n",
    "game1.initialize_graph()\n",
    "\n",
    "def get_game_graph(game):\n",
    "    return np.float32(nx.adjacency_matrix(game.graph).todense())\n",
    "\n",
    "def get_actions(game):\n",
    "    return list(itertools.combinations(list(game.players.keys()), 2))\n",
    "\n",
    "def get_action_space(game):\n",
    "    actions = get_actions(game)\n",
    "    return len(actions)\n",
    "\n",
    "def get_input_space(game):\n",
    "    return game.rules.nb_players**2\n",
    "\n",
    "tf.reset_default_graph()\n",
    "#These lines establish the feed-forward part of the network used to choose actions\n",
    "action_space = get_action_space(game1)\n",
    "input_space = get_input_space(game1)\n",
    "\n",
    "\n",
    "class experience_buffer():\n",
    "    def __init__(self, buffer_size = 10000):\n",
    "        self.buffer = []\n",
    "        self.buffer_size = buffer_size\n",
    "    \n",
    "    def add(self,experience):\n",
    "        if len(self.buffer) + len(experience) >= self.buffer_size:\n",
    "            self.buffer[0:(len(experience)+len(self.buffer))-self.buffer_size] = []\n",
    "        self.buffer.extend(experience)\n",
    "            \n",
    "    def sample(self,size):\n",
    "        buffer = np.array(self.buffer)\n",
    "        return buffer[np.random.choice(np.shape(buffer)[0], size, replace=False), :]\n",
    "    \n",
    "def updateTargetGraph(tfVars,tau):\n",
    "    total_vars = len(tfVars)\n",
    "    op_holder = []\n",
    "    for idx,var in enumerate(tfVars[0:total_vars//2]):\n",
    "        op_holder.append(tfVars[idx+total_vars//2].assign((var.value()*tau) + ((1-tau)*tfVars[idx+total_vars//2].value())))\n",
    "    return op_holder\n",
    "\n",
    "def updateTarget(op_holder,sess):\n",
    "    for op in op_holder:\n",
    "        sess.run(op)\n",
    "        \n",
    "\n",
    "class Q_Network():\n",
    "    def __init__(self):\n",
    "        #These lines establish the feed-forward part of the network used to choose actions\n",
    "        self.inputs = tf.placeholder(shape=[None, input_space],dtype=tf.float32)\n",
    "        self.Temp = tf.placeholder(shape=None,dtype=tf.float32)\n",
    "        self.keep_per = tf.placeholder(shape=None,dtype=tf.float32)\n",
    "\n",
    "        hidden = slim.fully_connected(self.inputs,64,activation_fn=tf.nn.tanh,biases_initializer=None)\n",
    "        hidden = slim.dropout(hidden,self.keep_per)\n",
    "        self.Q_out = slim.fully_connected(hidden,action_space,activation_fn=None,biases_initializer=None)\n",
    "        \n",
    "        self.predict = tf.argmax(self.Q_out,1)\n",
    "        self.Q_dist = tf.nn.softmax(self.Q_out/self.Temp)\n",
    "        \n",
    "        \n",
    "        #Below we obtain the loss by taking the sum of squares difference between the target and prediction Q values.\n",
    "        self.actions = tf.placeholder(shape=[None],dtype=tf.int32)\n",
    "        self.actions_onehot = tf.one_hot(self.actions,action_space,dtype=tf.float32)\n",
    "        \n",
    "        self.Q = tf.reduce_sum(tf.multiply(self.Q_out, self.actions_onehot), reduction_indices=1)\n",
    "        \n",
    "        self.nextQ = tf.placeholder(shape=[None],dtype=tf.float32)\n",
    "        loss = tf.reduce_sum(tf.square(self.nextQ - self.Q))\n",
    "        trainer = tf.train.GradientDescentOptimizer(learning_rate=0.0005)\n",
    "        self.updateModel = trainer.minimize(loss)\n",
    "        \n",
    "# Set learning parameters\n",
    "exploration = \"e-greedy\" #Exploration method. Choose between: greedy, random, e-greedy, boltzmann, bayesian.\n",
    "y = .99 #Discount factor.\n",
    "num_episodes = 20000 #Total number of episodes to train network for.\n",
    "tau = 0.001 #Amount to update target network at each step.\n",
    "batch_size = 32 #Size of training batch\n",
    "startE = 1 #Starting chance of random action\n",
    "endE = 0.1 #Final chance of random action\n",
    "anneling_steps = 200000 #How many steps of training to reduce startE to endE.\n",
    "pre_train_steps = 50000 #Number of steps used before training updates begin.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0\n",
      "Episode 10\n",
      "Episode 20\n",
      "Episode 30\n",
      "Episode 40\n",
      "Episode 50\n",
      "Episode 60\n",
      "Episode 70\n",
      "Episode 80\n",
      "Episode 90\n",
      "Episode 100\n",
      "Mean Reward: 78.95 Total Steps: 10100 e: 1\n",
      "Episode 110\n",
      "Episode 120\n",
      "Episode 130\n",
      "Episode 140\n",
      "Episode 150\n",
      "Episode 160\n",
      "Episode 170\n",
      "Episode 180\n",
      "Episode 190\n",
      "Episode 200\n",
      "Mean Reward: 80.36 Total Steps: 20100 e: 1\n",
      "Episode 210\n",
      "Episode 220\n",
      "Episode 230\n",
      "Episode 240\n",
      "Episode 250\n",
      "Episode 260\n",
      "Episode 270\n",
      "Episode 280\n",
      "Episode 290\n",
      "Episode 300\n",
      "Mean Reward: 81.0 Total Steps: 30100 e: 1\n",
      "Episode 310\n",
      "Episode 320\n",
      "Episode 330\n",
      "Episode 340\n",
      "Episode 350\n",
      "Episode 360\n",
      "Episode 370\n",
      "Episode 380\n",
      "Episode 390\n",
      "Episode 400\n",
      "Mean Reward: 81.06 Total Steps: 40100 e: 1\n",
      "Episode 410\n",
      "Episode 420\n",
      "Episode 430\n",
      "Episode 440\n",
      "Episode 450\n",
      "Episode 460\n",
      "Episode 470\n",
      "Episode 480\n",
      "Episode 490\n",
      "Episode 500\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (32, 100) for Tensor 'Placeholder:0', which has shape '(1, 1, 100)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-126-726c4ab2fecb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0;31m#We use Double-DQN training algorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0mtrainBatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmyBuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m                 \u001b[0mQ1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mq_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainBatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mq_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeep_per\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m                 \u001b[0mQ2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQ_out\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mtarget_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainBatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeep_per\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0mend_multiplier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainBatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/joshua/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/joshua/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    942\u001b[0m                 \u001b[0;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m                 \u001b[0;34m'which has shape %r'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 944\u001b[0;31m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m    945\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (32, 100) for Tensor 'Placeholder:0', which has shape '(1, 1, 100)'"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "q_net = Q_Network()\n",
    "target_net = Q_Network()\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "trainables = tf.trainable_variables()\n",
    "targetOps = updateTargetGraph(trainables,tau)\n",
    "myBuffer = experience_buffer()\n",
    "\n",
    "\n",
    "#create lists to contain total rewards and steps per episode\n",
    "jList = []\n",
    "jMeans = []\n",
    "rList = []\n",
    "rMeans = []\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    updateTarget(targetOps,sess)\n",
    "    e = startE\n",
    "    stepDrop = (startE - endE)/anneling_steps\n",
    "    total_steps = 0\n",
    "    \n",
    "    for i in range(num_episodes):\n",
    "        #Reset environment and get first new observation\n",
    "        if i % 10 == 0:\n",
    "            print(\"Episode {}\".format(i))\n",
    "        rules = Rules()\n",
    "        rules.nb_max_step = 100\n",
    "        rules.nb_players = 10\n",
    "        game1 = Game()\n",
    "        game1.rules = rules\n",
    "        player1 = Player()\n",
    "        player1.name = \"RL\"\n",
    "        player1.rules = rules\n",
    "        player1.type = EntityType.competitive_player\n",
    "        game1.add_player(player1)\n",
    "        \n",
    "        \n",
    "        player2 = Player()\n",
    "        player2.rules = rules\n",
    "        player2.name = \"Heuristic\"\n",
    "        player2.type = EntityType.competitive_player\n",
    "        strategy_builder = StrategyBuilder()\n",
    "        player2.strategy = strategy_builder.get_random_egoist_strategy()\n",
    "        game1.add_player(player2)\n",
    "        \n",
    "        game1.initialize_graph()\n",
    "        previous_centrality = 0\n",
    "        s = get_game_graph(game1).flatten()\n",
    "        rAll = 0\n",
    "        d = False\n",
    "        j = 0\n",
    "        while j < rules.nb_max_step:\n",
    "            j+=1\n",
    "            if exploration == \"greedy\":\n",
    "                #Choose an action with the maximum expected value.\n",
    "                a,allQ = sess.run([q_net.predict,q_net.Q_out],feed_dict={q_net.inputs:[s],q_net.keep_per:1.0})\n",
    "                a = a[0]\n",
    "            if exploration == \"random\":\n",
    "                #Choose an action randomly.\n",
    "                a = np.random.randint(action_space)\n",
    "            if exploration == \"e-greedy\":\n",
    "                #Choose an action by greedily (with e chance of random action) from the Q-network\n",
    "                if np.random.rand(1) < e or total_steps < pre_train_steps:\n",
    "                    a = np.random.randint(action_space)\n",
    "                else:\n",
    "                    a,allQ = sess.run([q_net.predict,q_net.Q_out],feed_dict={q_net.inputs:[s],q_net.keep_per:1.0})\n",
    "                    a = a[0]\n",
    "            if exploration == \"boltzmann\":\n",
    "                #Choose an action probabilistically, with weights relative to the Q-values.\n",
    "                Q_d,allQ = sess.run([q_net.Q_dist,q_net.Q_out],feed_dict={q_net.inputs:[s],q_net.Temp:e,q_net.keep_per:1.0})\n",
    "                a = np.random.choice(Q_d[0],p=Q_d[0])\n",
    "                a = np.argmax(Q_d[0] == a)\n",
    "            if exploration == \"bayesian\":\n",
    "                #Choose an action using a sample from a dropout approximation of a bayesian q-network.\n",
    "                a,allQ = sess.run([q_net.predict,q_net.Q_out],feed_dict={q_net.inputs:[s],q_net.keep_per:(1-e)+0.1})\n",
    "                a = a[0]\n",
    "            possible_actions = get_actions(game1)\n",
    "            action = [possible_actions[a]]\n",
    "            actions = list(game1.get_actions())\n",
    "            action.extend(actions)\n",
    "            game1.play_round(actions=action)\n",
    "            s1 = get_game_graph(game1).flatten()\n",
    "            centralities = nx.betweenness_centrality(game1.graph)\n",
    "            centrality = centralities[0]\n",
    "            if centrality == previous_centrality:\n",
    "                r = 0\n",
    "            elif centrality > previous_centrality:\n",
    "                r = 1\n",
    "            else:\n",
    "                r = -1\n",
    "            d = False\n",
    "            myBuffer.add(np.reshape(np.array([s,a,r,s1,d]),[1,5]))\n",
    "            \n",
    "            if e > endE and total_steps > pre_train_steps:\n",
    "                e -= stepDrop\n",
    "            \n",
    "            if total_steps > pre_train_steps and total_steps % 5 == 0:\n",
    "                #We use Double-DQN training algorithm\n",
    "                trainBatch = myBuffer.sample(batch_size)\n",
    "                Q1 = sess.run(q_net.predict,feed_dict={q_net.inputs:np.vstack(trainBatch[:,3]),q_net.keep_per:1.0})\n",
    "                Q2 = sess.run(target_net.Q_out,feed_dict={target_net.inputs:np.vstack(trainBatch[:,3]),target_net.keep_per:1.0})\n",
    "                end_multiplier = -(trainBatch[:,4] - 1)\n",
    "                doubleQ = Q2[range(batch_size),Q1]\n",
    "                targetQ = trainBatch[:,2] + (y*doubleQ * end_multiplier)\n",
    "                _ = sess.run(q_net.updateModel,feed_dict={q_net.inputs:np.vstack(trainBatch[:,0]),q_net.nextQ:targetQ,q_net.keep_per:1.0,q_net.actions:trainBatch[:,1]})\n",
    "                updateTarget(targetOps,sess)\n",
    "\n",
    "            rAll += r\n",
    "            s = s1\n",
    "            total_steps += 1\n",
    "            if d == True:\n",
    "                break\n",
    "        jList.append(j)\n",
    "        rList.append(rAll)\n",
    "        if i % 100 == 0 and i != 0:\n",
    "            r_mean = np.mean(rList[-100:])\n",
    "            j_mean = np.mean(jList[-100:])\n",
    "            if exploration == 'e-greedy':\n",
    "                print(\"Mean Reward: \" + str(r_mean) + \" Total Steps: \" + str(total_steps) + \" e: \" + str(e))\n",
    "            if exploration == 'boltzmann':\n",
    "                print(\"Mean Reward: \" + str(r_mean) + \" Total Steps: \" + str(total_steps) + \" t: \" + str(e))\n",
    "            if exploration == 'bayesian':\n",
    "                print(\"Mean Reward: \" + str(r_mean) + \" Total Steps: \" + str(total_steps) + \" p: \" + str(e))\n",
    "            if exploration == 'random' or exploration == 'greedy':\n",
    "                print(\"Mean Reward: \" + str(r_mean) + \" Total Steps: \" + str(total_steps))\n",
    "            rMeans.append(r_mean)\n",
    "            jMeans.append(j_mean)\n",
    "print(\"Percent of succesful episodes: \" + str(sum(rList)/num_episodes) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0\n",
      "Episode 10\n",
      "Percent of succesful episodes: 3.7%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x114461780>]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQggRJf4//fRku6yTbMIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114dbbd68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set learning parameters\n",
    "y = .99\n",
    "e = 0.1\n",
    "num_episodes = 20\n",
    "#create lists to contain total rewards and steps per episode\n",
    "jList = []\n",
    "rList = []\n",
    "winList = []\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(num_episodes):\n",
    "        #Reset environment and get first new observation\n",
    "        if i % 10 == 0:\n",
    "            print(\"Episode {}\".format(i))\n",
    "        rules = Rules()\n",
    "        rules.nb_max_step = 100\n",
    "        rules.nb_players = 10\n",
    "        game1 = Game()\n",
    "        game1.rules = rules\n",
    "        player1 = Player()\n",
    "        player1.name = \"RL\"\n",
    "        player1.rules = rules\n",
    "        player1.type = EntityType.competitive_player\n",
    "        game1.add_player(player1)\n",
    "        \n",
    "        \n",
    "        player2 = Player()\n",
    "        player2.rules = rules\n",
    "        player2.name = \"Heuristic\"\n",
    "        player2.type = EntityType.competitive_player\n",
    "        strategy_builder = StrategyBuilder()\n",
    "        player2.strategy = strategy_builder.get_random_egoist_strategy()\n",
    "        game1.add_player(player2)\n",
    "        \n",
    "        game1.initialize_graph()\n",
    "        \n",
    "        s = get_game_graph(game1).flatten()\n",
    "        \n",
    "        rAll = 0\n",
    "        previous_centrality = 0\n",
    "        d = False\n",
    "        j = 0\n",
    "        win = 0\n",
    "        #The Q-Network\n",
    "        while j < rules.nb_max_step:\n",
    "            j+=1\n",
    "            #Choose an action by greedily (with e chance of random action) from the Q-network\n",
    "            a, allQ = sess.run([predict,Qout],feed_dict={inputs1:s})\n",
    "            if np.random.rand(1) < e:\n",
    "                a[0] = np.random.randint(action_space)\n",
    "            #Get new state and reward from environment\n",
    "            action = None\n",
    "            possible_actions = get_actions(game1)\n",
    "            if a[0] is not 0:\n",
    "                action = [possible_actions[a[0]]]\n",
    "            else:\n",
    "                action = None\n",
    "            actions = list(game1.get_actions())\n",
    "            action.extend(actions)\n",
    "            game1.play_round(actions=action)\n",
    "            s1 = get_game_graph(game1).flatten()\n",
    "            centralities = nx.betweenness_centrality(game1.graph)\n",
    "            centrality = centralities[0]\n",
    "            if centrality == previous_centrality:\n",
    "                r = 0\n",
    "            elif centrality > previous_centrality:\n",
    "                r = 1\n",
    "            else:\n",
    "                r = -1\n",
    "            #print(centrality, previous_centrality, r)\n",
    "            #Obtain the Q' values by feeding the new state through our network\n",
    "            Q1 = sess.run(Qout,feed_dict={inputs1:s1})\n",
    "            #Obtain maxQ' and set our target value for chosen action.\n",
    "            maxQ1 = np.max(Q1)\n",
    "            targetQ = allQ\n",
    "            targetQ[0,a[0]] = r + y*maxQ1\n",
    "            #Train our network using target and predicted Q values\n",
    "            _,W1 = sess.run([updateModel,W],feed_dict={inputs1:s,nextQ:targetQ})\n",
    "            rAll += r\n",
    "            s = s1\n",
    "            previous_centrality = centrality\n",
    "            \n",
    "            opponent_centrality = centralities[1]\n",
    "            if centrality > opponent_centrality:\n",
    "                win += 1\n",
    "            if centrality == 1.0 and j > 20:\n",
    "                #Reduce chance of random action as we train the model.\n",
    "                e = 1./((i/50) + 10)\n",
    "                break\n",
    "        winList.append(win)\n",
    "        jList.append(j)\n",
    "        rList.append(rAll)\n",
    "rList = np.array(rList)\n",
    "print(\"Percent of succesful episodes: \" + str(np.sum(rList)/num_episodes) + \"%\")\n",
    "\n",
    "plt.plot(winList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
